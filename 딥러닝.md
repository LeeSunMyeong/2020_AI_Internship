# 딥러닝

## 딥러닝의 정의

- 딥 러닝은 컴퓨터들이 인간의 두뇌와 비슷한 모양의 대형 인공 신경망을 형성하는 일종의 기계 학습입니다.
- 딥 러닝에서는 대규모 인공 신경망에 학습 알고리즘과 지속적으로 증가하는 양의 데이터를 공급함으로써, "사고"하는 능력과 처리하는 데이터를 "학습"하는 능력을 지속적으로 개선합니다.
- "딥"이란 단어는 시간이 지나면서 축적되는 신경망의 여러 층을 의미하며, 신경망의 깊이가 깊어질수록 성능이 향상됩니다.
- 현재 대부분의 딥 러닝이 인간의 감독 하에 진행되지만, 자체 훈련과 독립적인 "학습"이 가능한 신경망을 구축하는 것이 목표입니다.
- 딥 러닝이란, 사람의 개입이 필요한 기존의 지도 학습(supervised learning)에 보다 능동적인 비지도 학습(unsupervised)이 결합돼 컴퓨터가 마치 사람처럼 스스로 학습할 수 있는 인공지능 기술입니다.
- 기술적으로 보면, 딥 러닝은 인공신경망(ANN, Artificial Neural Networks)에 기반한 일련의 기계 학습의 집합체로 컴퓨터에게 사람의 사고 방식을 가르치는 알고리즘이라고 할 수 있습니다.

## 딥러닝의 역사

MIT가 2013년을 빛낼 10대 혁신기술 중 하나로 선정하고 가트너(Gartner, Inc.)가 2014 세계 IT 시장 10대 주요 예측에 포함시키는 등 최근들어 딥 러닝에 대한 관심이 높아지고 있지만 사실 딥 러닝 구조는 인공신경망(ANN, artificial neural networks)에 기반하여 설계된 개념으로 역사를 따지자면 최소 1980년 Kunihiko Fukushima에 의해 소개 된 Neocognitron까지 거슬러 올라가야 한다.

1989년에 얀 르쿤과 그의 동료들은 오류역전파 알고리즘(backpropagation algorithm)에 기반하여 우편물에 손으로 쓰여진 우편번호를 인식하는 deep neural networks를 소개했다. 알고리즘이 성공적으로 동작했음에도 불구하고, 신경망 학습에 소요되는 시간(10 개의 숫자를 인식하기 위해 학습하는 시간)이 거의 3일이 걸렸고 이것은 다른분야에 일반적으로 적용되기에는 비현실적인 것으로 여겨졌다.

많은 요소들이 느린 속도에 원인을 제공했는데, 그 중 하나는 1991년 Jürgen Schmidhuber의 제자였던 Sepp Hochreiter에 의해 분석된 vanishing gradient problem(지역최솟값에 머무르게 되는 원인)이었다. 또한 불연속 시뮬레이션에서 초기 상태를 어떻게 선택하느냐에 따라 수렴이 안되고 진동 또는 발산하는 문제, 트레이닝셋에 너무 가깝게 맞추어 학습되는 과적합 (Overfitting) 문제, 원론적으로 생물학적 신경망과는 다르다는 이슈들이 끊임 없이 제기되면서 인공신경망은 관심에서 멀어졌고 90년대와 2000년대에는 서포트 벡터 머신 같은 기법들이 각광받게 된다.

본격적으로 딥 러닝이란 용어를 사용한 것은 2000년대 딥 러닝의 중흥기를 이끌어간다고 평가할 수 있는 제프리 힌튼과 Ruslan Salakhutdinov에 의해서이며, 기존 신경망의 과적합 문제를 해결하기 위해 이들은 unsupervised RBM(restricted Boltzmann machine)을 통해 학습시킬 앞먹임 신경망(Feedforward Neural Network)의 각 층을 효과적으로 사전훈련(pre-trainning)하여 과적합을 방지할 수 있는 수준의 initialize point를 잡았고, 이를 다시 supervised backpropagation를 사용하는 형태로 학습을 진행한다.

또한 2013년에는 신호처리학회인 ICASSP에서 RBM을 대체하여 과적합을 방지할 수 있는 Drop-out이라는 개념이 소개되면서 사전훈련 보다 훨씬 더 간단하고 강력한 형태로 과적합을 방지할 수 있게 되었다.

## 딥러닝이 주목받게 된 이유

첫 번째는 앞서 딥 러닝의 역사에서 언급한 바 있는 기존 인공신경망 모델의 단점이 극복되었다는 점이다. 그러나 과적합 문제만 해결되었다고 해서 느린 학습시간이 줄어드는 것은 아니다.

두 번째 이유로, 여기에는 하드웨어의 발전이라는 또 다른 요인이 존재 한다. 특히 강력한 GPU는 딥러닝에서 복잡한 행렬 연산에 소요되는 시간을 크게 단축시켰다.

세 번째 이유로 빅 데이터를 들 수 있다.

대량으로 쏟아져 나오는 데이터들, 그리고 그것들을 수집하기 위한 노력 특히 SNS 사용자들에 의해 생산되는 다량의 자료와 태그정보들 모두가 종합되고 분석 되어 학습에 이용될 수 있다.

- 인공신경망의 학습에 사용되는 트레이닝벡터는 이름이 붙어 있는(labeled) 데이터여야 하는데(supervised learning의 경우) 대량의 트레이닝셋 모두에 label을 달아주는 일은 불가능한 일이다. 이런 이유로 초기 학습에 사용되는 일부 데이터에 대해서만 지도학습(supervised learning)을 수행하고 나머지 트레이닝셋에 대해서는 비지도학습(unsupervised learning)을 진행하며, 학습된 결과는 기존 학습의 결과와 앞서 분석된 메타태그 정보들을 종합하여 인식기가 완성된다.

## 딥러닝의 다양한 분야

딥러닝은 다양한 분야, 특히 자동 음성 인식(ASR, automatic speech recognition)과 컴퓨터비전 분야에서 최고수준의 성능을 보여주고 있으며, 이들은 보통 딥러닝의 새로운 응용들의 지속적인 성능 향상을 위해 만들어진 TIMIT(Texas Instruments와 MIT가 제작한 음성 Database), MNIST(이미지 클러스터링을 위한 hand-written 숫자 이미지 데이터베이스로 National Institute of Standards and Technology가 제작) 등의 데이터베이스를 사용했다.

최근에는 Convolution Neural Networks 기반의 딥러닝 알고리즘이 뛰어난 성능을 발휘하고 있으며, 컴퓨터비전과 음성인식등의 분야에서 특히 탁월한 성능을 보이고 있다.

## 심층 신경망(Deep Neural Network, DNN)

심층 신경망(Deep Neural Network, DNN)은 입력층(input layer)과 출력층(output layer) 사이에 여러 개의 은닉층(hidden layer)들로 이뤄진 인공신경망(Artificial Neural Network, ANN)이다. 심층 신경망은 일반적인 인공신경망과 마찬가지로 복잡한 비선형 관계(non-linear relationship)들을 모델링할 수 있다.

예를 들어, 사물 식별 모델을 위한 심층 신경망 구조에서는 각 객체가 이미지 기본 요소들의 계층적 구성으로 표현될 수 있다. 이때, 추가 계층들은 점진적으로 모여진 하위 계층들의 특징들을 규합시킬 수 있다. 심층 신경망의 이러한 특징은, 비슷하게 수행된 인공신경망에 비해 더 적은 수의 유닛(unit, node)들 만으로도 복잡한 데이터를 모델링할 수 있게 해준다.

이전의 심층 신경망들은 보통 앞먹임 신경망으로 설계되어 왔지만, 최근의 연구들은 심층 학습 구조들을 순환 신경망(Recurrent Neural Network, RNN)에 성공적으로 적용했다. 일례로 언어 모델링(language modeling) 분야에 심층 신경망 구조를 적용한 사례 등이 있다.

합성곱 신경망(Convolutional Neural Network, CNN)의 경우에는 컴퓨터 비전(computer vision) 분야에서 잘 적용되었을 뿐만 아니라, 각각의 성공적인 적용 사례에 대한 문서화 또한 잘 되어 있다. 더욱 최근에는 합성곱 신경망이 자동 음성인식 서비스(Automatic Response Service, ARS)를 위한 음향 모델링(acoustic modeling) 분야에 적용되었으며, 기존의 모델들 보다 더욱 성공적으로 적용되었다는 평가를 받고 있다.

심층 신경망은 표준 오류역전파 알고리즘으로 학습될 수 있다. 이때, 가중치(weight)들은 아래의 등식을 이용한 확률적 경사 하강법(stochastic gradient descent)을 통하여 갱신될 수 있다.

![dnn1](./img/dnn1.png)

여기서, η는 학습률(learning rate)을 의미하며, C는 비용함수(cost function)를 의미한다. 비용함수의 선택은 학습의 형태(지도 학습, 자율 학습 (기계 학습), 강화 학습 등)와 활성화함수(activation function)같은 요인들에 의해서 결정된다. 예를 들면, 다중 클래스 분류 문제(multiclass classification problem)에 지도 학습을 수행할 때, 일반적으로 활성화함수와 비용함수는 각각 softmax 함수와 교차 엔트로피 함수(cross entropy function)로 결정된다.
softmax 함수는

![dnn2](./img/dnn2.png)

로 정의된다, 이때,  Pj 는 클래스 확률(class probability)을 나타내며,  Xj 와  Xk 는 각각 유닛 j로의 전체 입력(total input)과 유닛 k 로의 전체 입력을 나타낸다. 교차 엔트로피는

![dnn3](./img/dnn3.png)

로 정의된다, 이때, dj 는 출력 유닛 j 에 대한 목표 확률(target probability)을 나타내며, Pj 는 해당 활성화함수를 적용한 이후의 j 에 대한 확률 출력(probability output)이다.

## 심층 신경망의 문제점

기존의 인공신경망과 같이, 심층 신경망 또한 나이브(naive)한 방식으로 학습될 경우 많은 문제들이 발생할 수 있다. 그 중 과적합과 높은 시간 복잡도가 흔히 발생하는 문제들이다.

심층 신경망이 과적합에 취약한 이유는 추가된 계층들이 학습 데이터의 rare dependency의 모형화가 가능하도록 해주기 때문이다. 과적합을 극복하기 위해서 weight decay (l2–regularization) 또는 sparsity (l1–regularization) 와 같은 regularization 방법들이 사용될 수 있다. 그리고 최근에 들어서는 심층 신경망에 적용되고 있는 정규화 방법 중 하나로 dropout 정규화가 등장했다. dropout 정규화에서는 학습 도중 은닉 계층들의 몇몇 유닛들이 임의로 생략된다. 이러한 방법은 학습 데이터(training data)에서 발생할 수 있는 rare dependency를 해결하는데 도움을 준다.

오차역전파법과 경사 하강법은 구현의 용이함과 국지적 최적화(local optima)에 잘 도달한다는 특성으로 인해 다른 방법들에 비해 선호되어온 방법들이다. 그러나 이 방법들은 심층 신경망을 학습 시킬 때 시간 복잡도가 매우 높다. 심층 신경망을 학습시킬 때에는 크기(계층의 수 와 계층 당 유닛 수), 학습률, 초기 가중치 등 많은 매개변수(parameter)들이 고려되어야 한다. 하지만 최적의 매개변수들을 찾기 위해 매개변수 공간 전부를 확인하는 것은 계산에 필요한 시간과 자원의 제약으로 인해 불가능하다. 시간 복잡도를 해결하기 위해, 미니 배치(mini batch, 여러 학습 예제들의 경사를 동시에 계산), 드롭 아웃(drop out)과 같은 다양한 '묘책’들이 등장하였다. 또한, 행렬 및 벡터 계산에 특화된 GPU는 많은 처리량을 바탕으로 두드러지는 학습 속도 향상을 보여주었다.